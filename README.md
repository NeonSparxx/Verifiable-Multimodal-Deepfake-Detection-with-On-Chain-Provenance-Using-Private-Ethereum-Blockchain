The high pace of generative AI development has rendered the complex deepfakes indistinguishable to the human eye, and constitutes serious threats to journalism, integrity of evidence, social trust, and democratic processes. In this project, we present a new, completely localized, and GPU-accelerated multimodal deepfake detector which can analyze images, videos, and audio files in real-time and offer cryptographic evidence of each decision.
The detection pipeline combines three expert deep neural networks: an image forgery classifier implemented as a ResNet-50, a temporal attention and 3D convolutional network that takes video frame input, and audio deepfake detector based on transformers (that takes input in the form of raw waveform and spectrogram). Video processing is performed in a way that frames and audio are automatically extracted and assessed independently and fused by weighted ensemble, which presents state-of-the-art accuracy on benchmark datasets.
Its main innovation is the fact that it is built with the immutability of blockchain in an invisible manner. After inference is complete, the system automatically triggers a local Ganache Ethereum instance Solidity smart contract. A fully indexed PredictionLogged event is emitted by the contract with the following content; the filename, the binary prediction (real/fake), the confidence score (0.000000-1.000000), Unix timestamp, and the detector address. This operation is mined immediately and written permanently into the private chain.The users are given a normal Ethereum transaction hash and the outcome. The authenticity of reported outcome can be verified by any third party independently by:
•	Viewing the log of the events on the given chain
•	Rechecking the detector on the first file
•	Making sure you are getting the same results and timestamps.
